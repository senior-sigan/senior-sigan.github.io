<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta property="og:site_name" content="Ilya&#39;s digital garden">

  <link rel="icon" type="image/png" href="data:image/png;base64,iVBORw0KGgo=">

  <link rel="stylesheet" href="/app.css">

  
  <meta property="og:title" content="Projects">
  <meta property="og:type" content="article">
  

  
  <meta property="article:published_time" content="">
  <meta property="article:author" content="/">
  

  <title>
    Projects
  </title>

  
</head>

<body>
  <nav><ul>
    <li><a class="internal-link" href="/"><b>Ilya&#39;s digital garden</b></a></li>
    <li><a class="internal-link" href="about.html">About</a></li>
    <li><a class="internal-link" href="archive.html">Archive</a></li>
</ul></nav>
  <div class="wrapper">
    <main>

<article>
  <div>
    <h1>Projects</h1>
    
    <time datetime="2022-04-19T01:28:00+06:00">
      Created on Apr 19, 2022
    </time>
    
  </div>

  <div id="notes-entry-container">
    <content>
      <p>This is the index of my project notes grouped by categories.</p>
<h2>GameDev</h2>
<ul>
<li><a class="wikilink" href="/2016-04-26-multiplayer-game-on-the-ludum-dare-35">2016-04-26-multiplayer-game-on-the-ludum-dare-35</a></li>
<li><a class="wikilink" href="/2018-04-26-ludumdare-41">2018-04-26-ludumdare-41</a></li>
</ul>
<h2>Machine Learning</h2>
<ul>
<li><a class="wikilink" href="/2018-01-23-similar-images-search">2018-01-23-similar-images-search</a></li>
</ul>
<h2>Old university projects</h2>
<ul>
<li><a class="wikilink" href="/2014-12-20-audio-termometer">2014-12-20-audio-termometer</a></li>
<li><a class="wikilink" href="/2015-11-01-QRTransmitter">2015-11-01-QRTransmitter</a></li>
</ul>
    </content>

    <side style="font-size: 0.9em">
    
</side>

  </div>
</article>

<hr>

<p>Here are all the notes in this garden, along with their links, visualized as a graph. <i>(Use ctrl + scroll to zoom
    in-out)</i></p>

<script src="/scripts/libs/d3.min.js"></script>

<div id="graph-wrapper"></div>
<aside id="link-preview-block">
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2018-04-26-ludumdare-41">
        <div class="tooltip-content">
            <h1>Ludumdare 41</h1>
            <content>
                <p>В эти выходные, 21–22 апреля, мы командой <a href="http://catinthedark.itch.io/">CAT_IN_THE_DARK</a>, состоящей в этот раз только из <a href="https://vk.com/senior_sigan">меня</a> и <a href="https://vk.com/svetlanab7">Светы</a>, делали игру на тему “Combine 2 Incompatible Genres” в рамках мирового <a href="https://ldjam.com/">LudumDare</a>.</p>
<p><img alt="Лучшие игры нашей команды" src="/assets/ludumdare-41/0_4C78Pxmw8lbLXF0E.jpg" /></p>
<p>Обычно мы очень долго вымучиваем из темы какую-нибудь идею игры. Логично, нас обычно 4 человека и у каждого своя точка зрения и всем всё не нравится. А в этот раз было в 2 раза проще! Поэтому не долго думая, мы решили скрестить тетрис с чем-то ещё: со стрелялкой или с tower-defence. В итоге после первого дня комбинирования тетриса и стрелялки от первого лица, я остановился на tetris-tower-defence.</p>
<p><img alt="Первый вариант — стрелялка. Мне показалось это не интересным." src="/assets/ludumdare-41/1_cLX1sRWxR637cAq9Skwmpw.gif" /></p>
<p>Кстати, <a href="https://vk.com/old48">OLD48</a>, как gathering для ludum dare, является отличным местом для тестирования гипотезы gameplay вашей игры. Если относиться к игре, сделанной на людуме, как к MVP некоторого стартапа, то на самом деле у нас была какая-то галлюцинация о крутом gameplay, который понравится людям. Ха-ха. Конечно не понравится. Этот ludum нам показал, что никому не интересно играть в TowerDefence+Tetris с жизнями, баллами(ой не важно) и стараться набрать максимальный счёт в таблице рекордов. Вместо риска получить больше очков, люди просто спамили тетрис-блоками, чтобы не потерять жизни не набирая очков.</p>
<p>{% youtube 7GXo6YB7KZ0 %}
Первая версия и один из лучших игроков.</p>
<p>Поэтому в понедельник, спустя день после людума, я вечером переделал баланс игры и сместил его в другую сторону. Теперь мы предлагаем игрокам не набрать наибольший score, а попытаться играть в игру настолько долго, насколько возможно. Эдакий flappy-bird style.</p>
<p>В итоге весь геймплей стал завязан на Времени — это игровая «валюта», которую ты получаешь и которой платишь за «промахи» и «пропуски» коробок.</p>
<h2>Сюжет игры</h2>
<p>Главный герой — работник космической почтовой службы будущего. Он стоит на конвейере, вооруженный тетрис пушкой, и должен вставлять подходящие тетрис блоки в пролетающие мимо него коробки, в которых эти тетрис блоки отсутствуют. За пропуск коробки героя штрафую, отнимая 10 секунд времени игры, а за попытку вставить неподходящий блок, отнимают 3 секунды. За успешное заполнение коробки дают 5 секунд игрового времени. В самом начале игроку выдают «кредит» в размере 30 секунд игры. И естественно каждую секунду отнимают 1 секунду игрового времени. Таким образом теперь задача игрока — это продержаться как можно дольше, играя в игру.</p>
<p>{% youtube 7vaG9oPkJ8s %}
Финальная версия игры.</p>
<h2>СКАЧАТЬ ИГРУ</h2>
<p>Вы тоже можете поиграть в эту игру, скачав её с <a href="https://catinthedark.itch.io/rmtca">нашего сайта</a>. Она работает под windows, macOS, Linux.</p>
<p>План развития?
добавить глобальную таблицу рекордов
портировать под Android &amp; IOS
новый клевый арт?
Кстати, последние несколько людумов я делаю таймлапс разработки. Некоторые люди говорят, что это залипательно.</p>
<p>{% youtube fsnB2i9KHqs %}
Таймлапс разработки игры.</p>
            </content>
        </div>
    </div>
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2016-04-26-multiplayer-game-on-the-ludum-dare-35">
        <div class="tooltip-content">
            <h1>Multiplayer Game on the Ludum Dare 35</h1>
            <content>
                <p>That's our 9th Ludum Dare, so we decided to make something challenging this time. We've tried to create multiplayer action-horror-shooter thingy with two characters trying to kill each other. One is a werewolf (short-range attack, wide angle of view), another one is a hunter (long-range attack, small view angle and viewing distance). And yeah, that was pretty challenging indeed for some reasons.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/ag624l2r8596cancum0v.jpg" /></p>
<h2>Networking</h2>
<p>We've made our first network game for LD#34. It was quite primitive, a peer-to-peer game for two players. But it proved that our team can handle network-game-specific issues and make network game at least playable. This time we decided to go further and create a server which would interconnect all game instances into pairs. That is still quite simple client-server architecture, but it required lots of time to implement and some knowledge of websockets magic.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/jmfqgwma6k1jhibzg5pz.gif" /></p>
<h2>Dynamic shadows</h2>
<p>Our game is based on LibGDX engine which is quite simple and, of course, doesn't have any built-in shadow support. So, shadows were made using a bunch of black triangles, dozens of math and sorting obstacles by distance, from farther to closer.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/fc21bm8gb6sq6cb1pa32.png" /></p>
<h2>Collisions detection</h2>
<p>Trigonometry magicCharacters should not go through trees, right? LibGDX has built-in box2d engine support, but for such simple task, it adds so much overhead to code that we decided to make everything on our own. That required some math too, and sometimes led to funny bugs such as trees making you stuck inside them and tear you apart.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/wbat2vb8o2g8y99o4sx7.jpeg" /></p>
<h2>Soft torch beam effect</h2>
<p>Dynamic shadowsIt may look simple. But inside it carries some OpenGL vertex and fragment shaders magic. One of us spent 5 hours or something making this effect look properly and be configurable too. This soft-beam torch effect could be also achieved with gradient transparent bitmap, but it would be less challenging and less funny to make.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/2ahpcg84vfzxsfzkz7wi.gif" /></p>
<h2>Balancing and small details</h2>
<p>After basic game mechanics was complete, we decided to add some more features to fix the game balance and make it more interesting to play. First, we've made a wolf jump over the trees to compensate hunter's advantage in attack range, and then we've added traces to our characters to help them find each other in the dark forest. To balance a game a bit more, we've added sounds of characters' steps so players could hear each other walking. This also makes a game more atmospheric.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/27jo9zq7p9as61itbdhj.jpeg" /></p>
<p>After all, we are completely happy with the result and we hope you'll enjoy playing this. It's hard to find opponent sometimes, so be ready to grab your friend and play with him over the Internet.</p>
<p>We also had a page with game statistics and Telegram chat for everyone who wants to receive notifications about active players waiting for an opponent.</p>
<p><img alt=" " src="/assets/multiplayer-game-on-the-ludum-dare-35/bipv1x0897exsz3j3nu0.png" /></p>
<p>You can download and play our game from <a href="https://catinthedark.itch.io/za-bochok">here</a>.</p>
<p>Gameplay video:</p>
<p>{% youtube X_CfocY6BvQ %}</p>
<p>Also we have a development timelapse.</p>
<p>{% youtube qkEgv-Azkxk %}</p>
<p><em><a href="https://medium.com/cat-in-the-dark/multiplayer-game-on-the-ludum-dare-35-jam-oh-rly-77d5dd04d51c">originally posted on medium in 2016–04–26</a> by <a href="https://medium.com/@KirillLeyfer">Kirill Leyfer</a> and <a href="https://dev.to/senior_sigan">Ilya Siganov</a></em></p>
            </content>
        </div>
    </div>
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2014-12-20-audio-termometer">
        <div class="tooltip-content">
            <h1>Аудио Термометр</h1>
            <content>
                <p><img alt="Макетная плата" src="/assets/audio-termometer/fRyw9kv9jmMfIpEz.jpg" /></p>
<p>Существует как минимум 2 способа подключения периферии к любому смартфону — это блютуз и usb. Дополнительно можно рассматривать wifi, nfc, ик-порт. Сейчас наибольшей популярностью пользуется конечно же блютуз. Этот протокол стандартизирован, он удобный, беспроводной и распространенный, достаточно прост в применении. Так же ведутся работы над LE Bluetoooth с низким энергопотреблением. С usb всё намного хуже, так как не каждый смартфон поддерживает функцию двухсторонней передачи данных, кроме того, если понадобится сделать своё usb-устройство, то придется долго разбираться как его зарегистрировать и прочее.</p>
<p>Иногда не требуется вся мощь технологии блютуз, но тогда что использовать вместо него для подключения к смартфону различной периферии, будь то специальные сенсоры, считыватели кредитных карт, измерители скорости ветра или термометр? Как это ни странно, звучит — <strong>использовать аудиовход</strong>! В нашем распоряжении будет чудесный аналоговый интерфейс, без каких либо протоколов передачи данных. Можно будет отправлять обычный модулированный сигнал. Как ни парадоксально, но это именно то, что нужно для большинства проектов по созданию периферии для смартфонов.</p>
<p><img alt="Image for post" src="/assets/audio-termometer/MgkWSwcJ7VsSxI4Q.jpg" /></p>
<p>Не мы первые додумались до такого решения, уже существует несколько проектов на основе аудиовхода — это pressy(просто кнопка), kinsa — термометр, vaavud — измеритель скорости ветра. Кроме того существует библиотека для установления соединения между Arduino и андроидом по типу модема.</p>
<ul>
<li>Передача данных — бинарный протокол</li>
<li>Термометр</li>
<li>Осцилограф</li>
<li>Измерение скорости ветра</li>
<li>Велокомпьютер без gps</li>
<li>Различные сенсоры</li>
</ul>
<p>Мы же в итоге остановились на идее термометра.</p>
<ul>
<li><strong>Простота</strong> — нет накладных расходов на упаковку пакетов данных, передачу данных по среде передачи, восстановление ошибок. Если надо отправить один символ, то нет необходимости отправлять целый пакет в несколько байт, шифровать его и распаковывать.</li>
<li><strong>Энергосбережение</strong> — в отличие от блютуза, не требуется так много энергии для передачи данных, установление и поддержания связи. Хотя с учетом Bluetooth LE, тут конечно можно поспорить.</li>
<li><strong>Plug-and-play</strong> — для пользователя в конечном итоге такие устройства будут очень простыми. Необходимо только подключить периферию и всё. Не надо устанавливать соединение, проводить авторизацию и прочие ритуалы для настройки блютуза или wifi.</li>
<li><strong>Совместимость</strong> — аудиоразъем есть на каждом смартфоне. В отличие от usb-host, который есть только на некоторых устройствах.</li>
<li>Нет никакого, даже самого простого стандартного метода для передачи бинарных данных, поэтому всё придется писать с самого начала самому. Например, сделать обыкновенный модем, для передачи бинарных данных. Придется самим вручную исправлять помехи и восстанавливать данные.</li>
<li>Низкая скорость, так как есть ограничение в 44100Гц частоты дискретизации.</li>
<li>Расхождение технических показателей аудио интерфейса. Амплитуды выходных сигналов на разных устройствах могут отличаться.</li>
</ul>
<p>Тем не мене, если вам понадобилась передача данных, то логичнее использовать блютуз, а если нужен просто аналоговый вход, то лучше аудио интерфейса ничего не найти.</p>
<p>Однако, перед использованием этого интерфейса придётся решить ряд технических проблем.</p>
<p>Первая проблема заключается в том, что большинство смартфонов рассчитаны на то, что к аудио разъёму может подключаться только гарнитура. И вы сможете отправить или получить какой-то сигнал через аудио разъём только если смартфон будет уверен, что к нему подключена гарнитура. Как этого добиться?</p>
<p><img alt="Image for post" src="/assets/audio-termometer/npIKUHELuaDOb4sJ.jpg" /></p>
<p>Давайте посмотрим, как устроена телефонная гарнитура. Она состоит из штекера с 4-мя контактами, к двум нижним подключены левый и правый наушник, их сопротивление колеблется от 16 до 40 Ом. К верхнему контакту подключен микрофон, его сопротивление примерно 1.5 кОм, а третий снизу контакт — это заземление. Поэтому, в теории, чтобы смартфон принял наше устройство за гарнитуру, необходимо заменить наушники и микрофон резисторами с эквивалентными сопротивлениями. На практике оказалось, что достаточно заменить микрофон резистором на 1.5 кОм.</p>
<p>Следующий вопрос заключается в том, как модифицировать эту схему, чтобы она приносила какую-то пользу.</p>
<p>Самый простой вариант — это добавить в схему ключ параллельно резистору, который будет замыкать микрофон на землю. Смартфон распознаёт это действие как нажатие кнопки гарнитуры. Программа, запущенная на смартфоне может перехватить это событие и каким-то образом его интерпретировать. Например, универсальная кнопка Pressy работает по такому же принципу. Конечно, это довольно примитивный инструмент, который подойдёт только для самых простых устройств.</p>
<p><img alt="Image for post" src="/assets/audio-termometer/0ODG6g6m1ytQTx2B.jpg" /></p>
<p>Следующая схема значительно сложнее в реализации. В этой схеме аудио кабель используется как полнодуплексный канал связи, к которому подключается полноценное цифровое устройство. Телефон принимает данные на вход микрофона и отправляет их через выход наушников. Это универсальная схема, поскольку она позволяет подключить к телефону различные сложные цифровые устройства, однако проектирование такого устройства связано с большими трудностями, поскольку придётся разработать собственный протокол обмена данными между телефоном и цифровым устройством.</p>
<p>Следующий вариант схемы немного проще. Телефон генерирует звуковой сигнал и отправляет его на выходы гарнитуры. Сигнал проходит через какую-то электрическую схему, некоторым образом изменяется и подаётся на вход микрофона. Телефон принимает изменённый сигнал и каким-то образом его интерпретирует. Такая схема идеальна для проектирования различных аналоговых датчиков, так как в схеме будет присутствовать элемент, изменяющий, например, сопротивление, в зависимости от некоторых условий. Поэтому для проектирования аудиотермометра такая схема подходит лучше всего.</p>
<p>Теперь возникает вопрос, как на основе данной схемы реализовать термометр. Для нашей схемы отлично подойдёт термистор, элемент, меняющий сопротивление в зависимости от температуры. В итоге получаем следующую схему.</p>
<p><img alt="Image for post" src="/assets/audio-termometer/IiNnVcLYzND6CwvF.jpg" /></p>
<p>Ко входу микрофона подключен резистор на 1.5 кОм, к левому каналу подключен резистор сопротивлением 10 кОм, к правому каналу подключен термистор. К земле — резистор 220 Ом.</p>
<p>На левый и правый каналы подаётся синусоидальный сигнал частотой 4 кГц, в противофазе. Сигналы, проходя через термистор и резистор, суммируются и направляются на вход микрофона. Соответственно, при температуре в 25 градусов сопротивления на левом и правом каналах будут равны, поэтому при суммировании каналы дадут сигнал с близкой к нулю амплитудой. При повышении температуры сопротивление на одном из каналов будет падать, поэтому амплитуда суммы сигналов будет расти.</p>
<p><img alt="Image for post" src="/assets/audio-termometer/M7QngZkJyJO52i0U.jpg" /></p>
<p>Но, к сожалению, не всё так просто. Такое решение обладает целым рядом недостатков. Во-первых, у каждого устройства своя громкость, поэтому при одинаковой температуре разные телефоны могут показать разные значения. Во-вторых, падении температуры ниже 25 градусов амплитуда сигнала на выходе снова будет расти. Ну и, в-третьих, амплитуду сигнала необходимо перевести в градусы Цельсия.</p>
<p>Для того, чтобы свести недостатки к минимуму, система измерения температуры была немного переделана. Теперь программа автоматически подстраивает громкость на каждом канале таким образом, чтобы амплитуда выходного сигнала всегда была нулевая. Температуре же теперь соответствует разница амплитуд на двух каналах. Для автоматической подстройки амплитуд сигналов применяется система обратной связи.</p>
<p><img alt="Image for post" src="/assets/audio-termometer/qV5h5eUF-L1iym_A.jpg" /></p>
<p>В начале, как и раньше, мы отправляем сигнал в противофазе с одинаковой амплитудой на левый и правый каналы. После того, как на входе, с некоторой задержкой, появилась сумма этих сигналов, мы анализируем амплитуду суммы и принимаем решение, на каком из каналов необходимо уменьшить или увеличить громкость. После этого на выход отправляются сигналы с изменённой амплитудой, и программа вновь ждёт на вход сумму этих сигналов. Чтобы гарантировать, что амплитуда суммы сигналов изменилась именно за счёт изменений на входе, а не за счёт изменения температуры, на выход отправляется синхроимпульс частотой 6 кГц, и система анализирует амплитуду суммы сигналов только после того, как получит синхроимпульс.</p>
<p>Для того, чтобы не пытаться переводить шумы, помехи, синхроимпульс в температуру, необходимо проверять какой частоты сигнал пришел на вход. Для этого вычисляется спектр входящего сигнала с помощью быстрого Фурье преобразования. Если частота гармоники с наибольшей амплитудой в спектре совпадает с частотой генерируемого сигнала, то мы получили полезную информацию. Иначе — помехи или синхроимпульс. Тогда игнорируем эти данные. Выводим информацию о том, что невозможно определить температуру.</p>
<p>Вывод формулы для значения температуры. Термисторы характеризуются рядом параметров, такими, как максимальный допустимый ток, точность, сопротивление при определённой температуре (как правило, при 25°С). Одним из параметров, характеризующим степень изменения сопротивления в зависимости от температуры является коэффициент температурной чувствительности, обозначаемый B. Этот коэффициент рассчитывается на основе значений сопротивления при двух конкретных значениях температур. Во многих случаях этими температурами выбираются 25°С и 100°С. Коэффициент B измеряется в Кельвинах и вычисляется по следующей формуле: <span class="arithmatex"><span class="MathJax_Preview"><span class="arithmatex"><span class="MathJax_Preview">B = \frac{ln(R_1) - ln(R_2)}{1 / T_1 - 1 / T_2}</span><script type="math/tex">B = \frac{ln(R_1) - ln(R_2)}{1 / T_1 - 1 / T_2}</script></span></span><script type="math/tex"><span class="arithmatex"><span class="MathJax_Preview">B = \frac{ln(R_1) - ln(R_2)}{1 / T_1 - 1 / T_2}</span><script type="math/tex">B = \frac{ln(R_1) - ln(R_2)}{1 / T_1 - 1 / T_2}</script></span></script></span> где R1 и R2 - значения сопротивлений при температурах соответственно T1 и T2, выраженных в Кельвинах. Из этой формулы следуют и обратные: <span class="arithmatex"><span class="MathJax_Preview"><span class="arithmatex"><span class="MathJax_Preview">T_1 = \frac{1}{\frac{ln(R_1) - ln(R_2)}{B} + \frac{1}{T_2})}</span><script type="math/tex">T_1 = \frac{1}{\frac{ln(R_1) - ln(R_2)}{B} + \frac{1}{T_2})}</script></span></span><script type="math/tex"><span class="arithmatex"><span class="MathJax_Preview">T_1 = \frac{1}{\frac{ln(R_1) - ln(R_2)}{B} + \frac{1}{T_2})}</span><script type="math/tex">T_1 = \frac{1}{\frac{ln(R_1) - ln(R_2)}{B} + \frac{1}{T_2})}</script></span></script></span></p>
<p>Термисторы обладают высокой степенью нелинейности параметров, и термисторы различных моделей, даже при одинаковых значениях параметра B25/100 могут по разному изменять сопротивление в зависимости от температуры. Поэтому формула может лишь приблизительно оценить температуру.</p>
<p>Производители термистров всегда прилагают таблицы с зависимостями сопротивления от температуры.</p>
<p>Таким образом для определения температуры достаточно знать значение сопротивления термистора и коэффициент B. В нашем случае мы не можем снимать непосредственно значение напряжения с термистора, используя, например, схему делителя напряжения, поэтому необходимо каким-то образом выразить значение сопротивления через амплитуды выходных сигналов на левом и правом каналах. Логично предположить, что отношение <span class="arithmatex"><span class="MathJax_Preview"><span class="arithmatex"><span class="MathJax_Preview">\frac{A_1}{A_2} = \frac{R_1}{R_2}</span><script type="math/tex">\frac{A_1}{A_2} = \frac{R_1}{R_2}</script></span></span><script type="math/tex"><span class="arithmatex"><span class="MathJax_Preview">\frac{A_1}{A_2} = \frac{R_1}{R_2}</span><script type="math/tex">\frac{A_1}{A_2} = \frac{R_1}{R_2}</script></span></script></span>, где <span class="arithmatex"><span class="MathJax_Preview"><span class="arithmatex"><span class="MathJax_Preview">R_1</span><script type="math/tex">R_1</script></span></span><script type="math/tex"><span class="arithmatex"><span class="MathJax_Preview">R_1</span><script type="math/tex">R_1</script></span></script></span> - сопротивление термистора.
Тогда получаем формулу: <span class="arithmatex"><span class="MathJax_Preview"><span class="arithmatex"><span class="MathJax_Preview">T = 1 / ((ln(R_2 * A_1/ A_2) - ln(R_1)) / B + 1 / T_1)</span><script type="math/tex">T = 1 / ((ln(R_2 * A_1/ A_2) - ln(R_1)) / B + 1 / T_1)</script></span></span><script type="math/tex"><span class="arithmatex"><span class="MathJax_Preview">T = 1 / ((ln(R_2 * A_1/ A_2) - ln(R_1)) / B + 1 / T_1)</span><script type="math/tex">T = 1 / ((ln(R_2 * A_1/ A_2) - ln(R_1)) / B + 1 / T_1)</script></span></script></span>.
В нашем случае получаем <span class="arithmatex"><span class="MathJax_Preview"><span class="arithmatex"><span class="MathJax_Preview">T = 1 / ((ln(10000 * Al/ Ar) - ln(10000)) / 4300 + 1 / 298)</span><script type="math/tex">T = 1 / ((ln(10000 * Al/ Ar) - ln(10000)) / 4300 + 1 / 298)</script></span></span><script type="math/tex"><span class="arithmatex"><span class="MathJax_Preview">T = 1 / ((ln(10000 * Al/ Ar) - ln(10000)) / 4300 + 1 / 298)</span><script type="math/tex">T = 1 / ((ln(10000 * Al/ Ar) - ln(10000)) / 4300 + 1 / 298)</script></span></script></span>, где B = 4300К, T1 = 298К, R1 = 10000 Ом, R2 = 10000 Ом</p>
<p>Как итог наших теоретических исследований, представим андроид-приложение аудиотермометр. Оно определяет температуру с точностью до 1 градуса, немного инертно но в целом дает реальную температуру. Конечно если задаться целью получить строго значение температуры с точностью до сотых долей, то лучше использовать диоды или еще лучше, готовые термометры, которые посылают значение температуры каким-то сигналом и считывать его аудио входом. Тем не менее с научной и практической точки зрения можно с уверенностью утверждать, что можно выделить некоторое множество проектов, которые было бы удобнее всего реализовывать именно через аудио интерфейс на смартфоне. Такие решения будут изящнее и миниатюрнее, удобнее в использовании, чем сторонние платы, подключаемые через блютуз или usb к смартфону. Существующие финансово успешные проекты подтверждают это.</p>
<ol>
<li><a href="http://electronics.stackexchange.com/questions/38417/how-do-volume-control-headphones-work">How do volume control headphones work?</a></li>
<li><a href="http://www.whence.com/minimodem/">Minimodem — general-purpose software audio FSK modem</a></li>
<li><a href="https://www.sparkfun.com/products/retired/10331">Audio Jack Modem for iPhone and Android</a></li>
<li><a href="http://www.fastcolabs.com/3030202/why-the-best-way-into-your-customers-iphone-is-the-headphone-jack">Why The Best Way Into Your Customer’s iPhone Is The Headphone Jack</a></li>
<li><a href="http://habrahabr.ru/post/196374/">Простыми словами о преобразовании Фурье</a></li>
</ol>
<p>Авторы статьи: <a href="https://medium.com/u/23ab90a702cf?source=post_page-----3ce480b9a8d0----------------------">Ilya Siganov</a> и <a href="https://medium.com/u/b4cf221ae11a?source=post_page-----3ce480b9a8d0----------------------">Кирилл Лейфер</a></p>
<p><a href="https://github.com/cat-in-the-dark/AudioThermometer">Исходный код приложения</a></p>
            </content>
        </div>
    </div>
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2015-11-01-QRTransmitter">
        <div class="tooltip-content">
            <h1>QRTransmitter</h1>
            <content>
                <p>На днях мне пришла в голову странная идея. В действительности не такая странная, так, обычная. Просто почему бы не написать приложение под Android для передачи файлов между устройствами с помощью <a href="https://ru.wikipedia.org/wiki/QR-код">QR кодов</a>.</p>
<p><img alt="QR transmitter app image" src="/assets/QRTransmitter/qrimage.jpg" /></p>
<p>Да, я снова взялся за старое, не достаточно мне было <a href="https://www.youtube.com/watch?v=BZ4PDgjlmb4">передачи данных вспышкой</a>, а также через аудио разъём. Поэтому опять появилась идея с нестандартным способом отправки файлов. Закономерно спросить, а что здесь такого особенного? QR и так позволяет отправлять небольшие кусочки информации, даже бинарной(около 2953 байт). Но только представьте как это прикольно выглядит — один смартфон очень быстро меняет на своем экране QR коды, в то время как другой считывает их камерой. Никаких bluetooth, wifi, irda и прочей беспроводной магии. А QRTransmitter — вот это действительно <em>беспроводная</em> передача! А скорость? По моим расчетам в худшем случае будет приблизительно 1кб/с. Возможно получиться ускорить до 5–6кб/с, пока не знаю.</p>
<p>Ближе к делу. За один вечер пока получилось сделать только генератор кодов. Приемник еще обдумываем вместе с <a href="https://medium.com/@KirillMegabozya">Кириллом</a>. А пока можно посмотреть забавный ролик. Потом обязательно покажу как будет работать приемник и расскажу больше технических деталей. А как же, даже в таком приложении будут интересные проблемы, например, синхронизация передатчика и приемника, выбор оптимальной частоты, определение начала и остановки.</p>
<p>{% youtube FdU0Ge9PQX8 %}</p>
<p>Для друзей программистов — пишем андроиде приложение на scala+gradle. Исходники <a href="https://github.com/cat-in-the-dark/QRTransmitter">тут</a>.</p>
            </content>
        </div>
    </div>
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2018-01-23-similar-images-search">
        <div class="tooltip-content">
            <h1>Поиск похожего изображения</h1>
            <content>
                <p>Небольшой отчет о создании приложения KawaiiSearch — поиска похожих фотографий с помощью сверточной нейросети и kNN</p>
<blockquote>
<p>tl;dr; Качаем фотографии из интернетов. Натренированной нейросетью VGG19 вычисляем 4096-мерные вектора каждого изображения. Косинусной метрикой находим ближайшего соседа к целевой картинке. Получаем наиболее похожие картинки в каком-то смысле. Profit!<br />
<a href="https://github.com/senior-sigan/KawaiiSearch">Source code</a>.</p>
</blockquote>
<h2>Введение</h2>
<p>Еще каких-то 5 лет назад, чтобы сделать свой поиск по картинкам, приходилось погружаться в тонкости машинного зрения. Нужно было придумывать то, каким образом преобразовать картинку в некоторый индекс, отпечаток, по которому можно найти другую, похожую на неё. Судя по всему, для этих целей могли использовать перцептивные хеши и вариации, разные преобразования характеристик изображений и даже каскады Хаара. В общем, всё это напоминало классические алгоритмы эпохи до машинного обучения, когда исследователям основываясь на их восприятии самим приходилось придумывать некоторые модели. Это всё безумно интересно и серьезно, можно защитить не один диплом и диссертацию. Но что примечательно, сейчас существует достаточно простой способ для построения своего собственного движка поиска похожих картинок и начать решать свои бизнес задачи немного проще, чем это было раньше.</p>
<h2>Что такое “похожие” изображения</h2>
<p><img alt="Sheepdog or mop?" src="/assets/similar-images-search/1_jeCYjspklUIiXJb6lYPCTQ.jpg" /></p>
<p>Прежде чем мы рассмотрим существующие подходы, необходимо правильно поставить вопрос — определить метрику похожести изображений. Но проблема подстерегает нас сразу, так как эта метрика может отличаться от задачи к задаче. Например, нам нужно находить исходное изображение по черно белому экземпляру. А может, необходимо находить картинки близкие по цветовой гамме. Возможна и постановка задачи, когда похожими считаются изображения со схожими формами объектов. А будет ли похожи фотографии одной и той же собаки в разных ракурсах или похожи фотографии разных собак, но в одном ракурсе.</p>
<p>Как видите, есть некоторые трудности в постановке задачи. Обычно даже не говорят, что две фотографии похожи, а рассматриваю некоторую величину похожести от, скажем, нуля — совершенно похожи, до бесконечности — совершенно не похожи. Измерение этой величины будет зависеть от той формы индексов, которые будет давать некоторый алгоритм; это может быть расстояние Хемминга или расстояние между точками в многомерном пространстве, или ещё что-то. Выбор метрики естественно будет влиять на результат не меньше, чем сам алгоритм поиска признаков в изображениях.</p>
<h2>Обзор существующих классических решений</h2>
<p>Если посмотреть на обычные алгоритмические методы сравнения изображений, то в основном всё сводится к вычислению некоторой хеш функции над изображением, а потом вычислению расстояния, например, Хэмминга между двумя значениями хешей. Чем меньше расстояние, тем больше картинки похожи между собой.</p>
<p>Далее начинается типичный для алгоритмических моделей путь выбора некоторой магической функции, которая будет сохранять в себе похожесть изображений. Один из примеров таких функций — это <a href="https://habrahabr.ru/post/120562/">перцептивный хеш</a>. В этом подходе с помощью <a href="https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%81%D0%BA%D1%80%D0%B5%D1%82%D0%BD%D0%BE%D0%B5_%D0%BA%D0%BE%D1%81%D0%B8%D0%BD%D1%83%D1%81%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%B5%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5">дискретного косинусного преобразования</a> оставляют так называемые нижние частоты, в которых сконцентрировано больше информации о форме изображения, чем о его цветовых характеристиках. В итоге большое изображение превращается в 64-битный хеш.</p>
<p>Есть еще несколько алгоритмов, даже на основе <a href="https://habrahabr.ru/post/198338/">каскадов Хаара</a>, но в результате так или иначе, алгоритм очень сильно страдает от преобразований над изображением: от поворотов, отражений, изменений размера, модификации цветности. Но тем не менее они очень быстро работают. Их можно использовать для поиска дубликатов с незначительными искажениями. Но для поиска изображениях, в которых “похожие” определяются в том смысле, что на них изображены коты, а не собаки, алгоритмы этого типа не подходят, да в принципе этого от них и не требуют. Забавно, что еще в 2011 году в комментариях к статьям писали, что невозможно написать такой алгоритм для кошек-собак.</p>
<p>Предлагаемый подход весьма наивный и простой, основывается на использовании машинного обучения и нейросетей. Так сразу в лоб и не совсем понятно чему надо обучать модель. Мы сами не можем сформулировать понятие “похожесть”. Тем не менее есть способ, и для его использования нам понадобится для начала решить задачу классификации.</p>
<h2>Классификация изображений</h2>
<p>На качественно ином уровне задачу классификации изображений начали решать с 2013 года. Тогда на наборе данных ImageNet пробили барьер в 15% ошибок классификации тысячи видов объектов. С тех пор за 5 лет было спроектировано и натренированно очень много разных моделей нейросетей, и был пробит барьер в 5% ошибок. Самыми успешными из них считаются: <a href="https://arxiv.org/abs/1409.1556">VGG16</a>, <a href="https://arxiv.org/abs/1512.03385">ResNet50</a>, <a href="https://arxiv.org/abs/1512.00567">Inception</a>, <a href="https://arxiv.org/abs/1409.4842">GoogLeNet</a> и много других. Большинство их них построено на основе <a href="http://cs231n.github.io/convolutional-networks/">свёрточных нейросетей</a>.</p>
<p>На рисунке вы можете посмотреть как выглядит схематически архитектура <a href="https://blog.heuritech.com/2016/02/29/a-brief-report-of-the-heuritech-deep-learning-meetup-5/">VGG16</a>.</p>
<p><img alt="VGG16" src="/assets/similar-images-search/1_dMRA5zbKqLX4rRul_X2gkA.png" /></p>
<p>Слои нейросети на изображении состоят из набора разных фильтров-сверток. Каждый из фильтров отвечает за поиск определенного шаблона, и когда он находит некоторый участок изображения, в котором есть этот узор, то фильтр посылает сигнал в следующий слой. В свою очередь сигналы предыдущего слоя составляют новое изображение для следующего слоя. На рисунке архитектуры VGG16 вы можете видеть, что сначала было цветное RGB изображение размера 224x224 пикселей с 3 каналами(red, green, blue). Потом после прохода первого слоя сверток у нас получилось изображение размера 224x224 пикселей с 64 каналами. Эти каналы уже представляют не цвета, а результаты работы каждого из 64 фильтров-свёрток. И так далее, до изображения 7x7 пикселей с 512 каналами.</p>
<p><img alt="Свёртка ищет бублик" src="/assets/similar-images-search/1_aIJ-Dm4mxEwC-Jpf7oxf4g.png" />
<em>Свёртка ищет бублик: <a href="https://www.youtube.com/watch?v=p_7GWRup-nQ">https://www.youtube.com/watch?v=p_7GWRup-nQ</a></em></p>
<p>Строя каскады свёрточных слоёв и обучая модель, вы получаете слои, содержащие в себе абстракции изображений. Первые слои в себе могут содержать мелкие детали: линии. Далее идут комбинации деталей — фигуры. Следующие слои уже могут содержать формы, а в конце целые объекты.</p>
<p><img alt=" " src="/assets/similar-images-search/1_v4l_IajKqOm53Z7U34bkKQ.jpg" />
<em>Feature Visualization of Convnet trained on ImageNet from [Zeiler &amp; Fergus 2013]</em></p>
<p>Обратите внимание еще на одну интересную особенность свёрточных слоев в этой модели: каждый следующий слой “толще”, так как в нём больше фильтров, но “меньше”, так как изображение специально уменьшают с помощью операции MaxPooling (субдискретизация). Используют этот прием по следующей причине: важнее факт детекции некоторого признака-объекта, чем знание точного расположения этого объекта на изображении. Именно поэтому берут максимум внутри небольшого окошка, тем самым создавая карту расположений признаков.</p>
<p><img alt="" src="/assets/similar-images-search/1_hrWnZ25CNMAEs-34BThqsA.png" />
<em>Max Pool 2x2, <a href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a></em></p>
<p>Ближе к выходу модели у нас имеется маленькое изображение — карта признаков размера 7x7 пикселей с 512 фильтрами. По этой трёхмерной карте всё еще невозможно сделать предсказания классов объектов на изображении — котик или собака. Для того чтобы перейти уже к предсказаниям классов, эту карту укладывают на плоскости с помощью операции Flatten и соединяют с полносвязным скрытым слоем из 4096 нейронов. А дальше классическая схема: еще один скрытый слой с 4096 нейронами и выходной слой с 1000 нейронами, каждый из которых выдает вероятность принадлежности к одному из 1000 классов в задаче ImageNet.</p>
<h2>Fine Tuning и переиспользование модели</h2>
<p>Как оказалось, сети обученные на данных ImageNet можно переиспользовать для других задач компьютерного зрения. Например, у нас задача отличать кошку от собаки. Вам не надо создавать свою модель CatDogVGG, искать миллионы картинок и обучать с нуля сеть. Всё куда проще! Вы берёте <em>предобученную модель</em> VGG, срезаете последние полносвязные слои нейронов, отвечающие за финальную классификацию(да, так можно), оставляя только внутренние 4096 нейронов, которые соединяете со своими 2 нейрона для выхода кошка-собака. Получается, что вам нужно будет только дообучить модель этим 2*4096 связям, что делается легко и быстро.</p>
<p>Какой физический смысл в срезании последнего слоя сети и подстановки нового? Оказывается, что все слои свертки внутри себя заключают способность “понимать” изображение. А поскольку обучение происходило на тысяче разных классов, то и обобщающая способность этих слоев достаточно сильная. В итоге внешние 4096 нейронов на самом деле выдают вектор характеристик(признаков) любого изображения в целом. Поэтому для того чтобы проходила наша классификация, отличная от изначальной, нам остается дообучить нейросеть только и только переводить этот 4096-мерный вектор в наш вектор предсказаний принадлежности классов, не меняя существующую глубокую свёрточную сеть.</p>
<p>Подобный финт можно провернуть не только с VGG, но и с другими свёрточными архитектурами распознавания изображений. Для этой цели в библиотеке Keras есть даже специальные конструкты, которые вы можете изучить это в разделе <a href="https://keras.io/applications/">keras-applications</a>. Распознавание образов еще никогда не было таким простым!</p>
<h2>Поиск похожих изображений с помощью нейросети</h2>
<p>Как мы поняли из предыдущего параграфа, срезанная нейросеть производит по своей сути извлечение признаков из изображения и переводит изображение в осмысленный вектор. Получение такого вектора раньше требовало экспертной оценки и придумывания очередного алгоритма хеширований. Полученные теми методами вектора (64-битные хешсуммы) заключали в себе информацию, в лучшем случае, о контурах и простых формах в целом. Нейросеть же даёт как минимум 4096-мерное представление, в котором заключена и форма, и цвет, и целые объекты.</p>
<p>Хорошо, нами получен вектор признаков изображения, что мы делаем дальше? Считать расстояние Хэмминга, как мы это делали с хешами, тут бессмысленно. Здесь мы должны использовать другой подход. Представьте, каждый из векторов куда-то направлен в пространстве, это направление характеризует изображение. Если мы посчитаем вектора для множества картинок, то логично предположить, что похожие картинки будут иметь вектора характеристик расположенные в пространстве близко. Отличной метрикой близости векторов в многомерном пространстве служит <a href="https://ru.wikipedia.org/wiki/Векторная_модель#Косинусное_сходство">косинусная метрика</a>, хорошо себя зарекомендовавшая в задачах классификации текстов.</p>
<p><img alt="Косинусная метрика" src="/assets/similar-images-search/1_2dwMgH7oScs3cxjy4Scb4Q.png" />
<em>Косинусная метрика</em></p>
<p>Чем меньше метрика, тем ближе объекты в векторном пространстве, тем больше похожи изображения по “мнению” нейросети.</p>
<h2>Собираем модель как конструктор</h2>
<p>Отлично, мы знаем теорию, знаем как получить представление нейросети об изображениях, знаем как сравнивать эти представления. Осталось дело за малым — собрать всё воедино.</p>
<p>Я предлагаю построить веб-приложение, похожее на Google Image Search. Для его построения нам понадобятся следующие библиотеки для Python3:</p>
<ul>
<li><a href="https://keras.io/">Keras</a> и <a href="https://www.tensorflow.org/">Tensorflow</a> для работы с нейросетями;</li>
<li>Numpy (a.k.a np) для математических функций;</li>
<li><a href="http://scikit-learn.org/">Sklearn</a> для алгоритма ближайших соседей и косинусной метрики;</li>
<li><a href="http://flask.pocoo.org/">Flask</a> для веба;</li>
<li>Pandas, pillow, scipy, h5py для разных вспомогательных нужд.</li>
</ul>
<p>Ещё нужно откуда-то взять много изображений на одну тематику. Я скачал все фотографии из блога <a href="http://tokyo-fashion.tumblr.com/">tokio-fashion</a> (около 50 тысяч фото), надеясь что нейросеть будет находить похожие образы или позы или еще что-нибудь. Кстати анализ fashion-индустрии это отдельная интересная область исследований!</p>
<p>Опишем базовые use-cases, которые мы хотим реализовать:</p>
<ul>
<li>пользователь заходит на страницу;</li>
<li>пользователь жмёт кнопку “мне повезет”, тем самым выбирая случайную картинку из всего набора данных;</li>
<li>сервер ищет методом ближайших соседей K самых близких вектора к случайно выбранному, эти K векторов будут описывать самые похожие картинки;</li>
<li>пользователь видит на странице исходную картинку и 9 похожих с метрикой похожести в подписи.</li>
</ul>
<p>Как делать веб часть и так все знают, поэтому рассмотрим наиболее неясные шаги.</p>
<h2>Векторизация базы фотографий</h2>
<p>Как мы уже знаем, для векторизации нам нужно отрезать один из последних слоев предобученной нейросети. Это операция распространенная, поэтому в библиотеке Keras нам уже доступны из коробки, во-первых, сама <a href="https://keras.io/applications/#vgg16">модель с весами</a> и, во-вторых, возможность не включать последний слой. Это делается следующим образом:</p>
<pre class="highlight"><code class="language-python">from keras.applications import VGG19

model = VGG19(weights='imagenet', include_top=False)</code></pre>
<p>Для более тонкой настройки можно указать имя определенного слоя. Как найти имя слоя — это отдельный анекдот, поэтому я смотрел в <a href="https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py#L149">исходники</a> модели.</p>
<pre class="highlight"><code class="language-python">from keras.applications import VGG19
from keras.engine import Model

bm = VGG19(weights='imagenet')
model = Model(inputs=bm.input, outputs=bm.get_layer('fc1').output)</code></pre>
<p>После того как у вас загружена модель, она, кстати, будет реально загружать из интернета веса, можно конвертировать все изображения в вектора с помощью метода <code>predict</code>, что логично, так как мы “предсказываем” этот вектор.</p>
<pre class="highlight"><code class="language-python">from keras.preprocessing import image
from keras.applications.vgg19 import preprocess_input

img = image.load_img(path, target_size=(224, 224)) # чтение из файла
x = image.img_to_array(img)  # сырое изображения в вектор
x = np.expand_dims(x, axis=0)  # превращаем в вектор-строку (2-dims)
x = preprocess_input(x) #  библиотечная подготовка изображения
vec = model.predict(x).ravel()
# ... PROFIT!</code></pre>
<p>Теперь всё тайное стало явью, и осталось дело техники — итерироваться по всем изображениям и для каждого из него произвести векторизацию. Потом сохранить эти вектора в БД или csv файла, не важно. Это мы оставим за <a href="https://github.com/blan4/KawaiiSearch/blob/master/src/vectorize_image.py">кулисами</a>.</p>
<h2>Поиск похожего методом kNN</h2>
<p>Далее нам нужно реализовать поиск ближайших векторов к целевому вектору с помощью косинусной метрики. В мире маш.обуча. не принято писать такие низкоуровневые задачи, поэтому мы переиспользуем код для алгоритма обучения без учителя — ближайшие соседи. В библиотеке sklearn есть специальный класс <a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors">NearestNeighbors</a>, которому можно указать метрику по которой он будет искать ближайших соседей к целевому объекту. Подготовка этого компонента будет выглядеть следующим образом:</p>
<pre class="highlight"><code class="language-python">from sklearn.neighbors import NearestNeighbors

knn = NearestNeighbors(metric='cosine', algorithm='brute')
vecs = load_images_vectors() #  а это мы уже сделали!
knn.fit(vecs)</code></pre>
<p>Мы выбрали <code>cosine</code> метрику и активировали полный перебор, загрузили все вектора в <code>knn</code> методом <code>fit</code>. Обычно этот метод запускает обучение, но в данном случае он просто сохранит все вектора внутри объекта <code>knn</code>, так как это алгоритм обучения без учителя.</p>
<p>Чтобы получить ближайших соседей, то есть похожие изображения, пишем следующе:</p>
<pre class="highlight"><code class="language-python">filenames = load_images_filenames()
vec = load_target_image()

dist, indices = knn.kneighbors(vec, n_neighbors=10)
similar_images = [
    (filenames[indices[i]], dist[i]) 
    for i in range(len(indices))
]</code></pre>
<p>В <code>similar_images</code> у нас будет лежать массив из 10 пар: имя файла и значение похожести по метрике, которая чем меньше, тем более похожее изображение к целевому. Всё, теперь этот список можно отдавать на фронтенд и рисовать красивую галерею. Изменяя параметр <code>n_neighbours</code> можно менять количество возвращаемых соседей, которые упорядочены по увеличению метрики, то есть дальше будут более непохожие картинки.</p>
<p>Тонкий момент. Функция <code>load_images_filenames()</code> возвращает список файлов ровно в том же порядке, в котором они перечислены в массиве <code>load_images_vectors()</code>, так как нам нужно точное соответствие вектора картинке.</p>
<h2>Результат</h2>
<p>Теперь вы видите, что с точки зрения кода задача теперь стала весьма простой. Но это всё благодаря развитию нейросетей и добрым экспериментаторам, которые выкладывают предобученные модели в интернет, иначе вам пришлось бы это всё самим обучать очень долго и мучительно.</p>
<p>А что в результате получилось? С моим результатом вы можете ознакомиться на сайте <a href="http://sigan.1der.link/kawaii_search">kawaii-search</a>, исходники которого доступны на <a href="https://github.com/blan4/KawaiiSearch">github</a>. Всё это крутиться на сервере <a href="https://cloud.google.com/compute/docs/machine-types">google-cloud n1-standard-1</a> c 3.75GB RAM чего не хватает и пришлось добавить еще столько же swap. Так как задача предсказания не сильно сложная, то видеокарта не нужна.</p>
<p>А в каком смысле теперь определено “похоже”. В случае с fashion датасетом, похожими считаются изображения, на которых есть объекты одних классов. Например, фотографии с только с портфелями, только с обувью одного типа, портреты, прически, руки. Смотрите сами:</p>
<p><img alt="Портфели" src="/assets/similar-images-search/1_JcWGJYElsBfOre5MWjiYBQ.jpg" /></p>
<p><img alt="Обувь" src="/assets/similar-images-search/1_OOVwoR09K3KFi5jESyubag.jpg" /></p>
<p><img alt="Колье, чокер" src="/assets/similar-images-search/1_Trtn711gR6-Dj7d7Yh3ukg.jpg" /></p>
<p>Что здесь интересного? Сеть сама решила что для нее похожее. Мы это не контролировали, оно получилось само. Мы потеряли некоторый контроль, но мы можем его вернуть, если сделаем обучения сами. И меня впечатляет то, что я не знаю как можно всё это сделать обычными алгоритмическими методами.</p>
<p>Кстати, на загруженных пользователем фотографиях поиск тоже работает. Обратите внимание, что здесь похожесть выражается в том, что на всех картинках есть один и тот же предмет — деревянный меч. Датасет в этом примере другой и модель немного хуже, поэтому есть ошибки.</p>
<p><img alt=" " src="/assets/similar-images-search/1_q13lid2-vXlvogF7ITfBng.jpg" />
<em>Похож = есть один и тот же предмет</em></p>
<h2>Что можно с этим делать</h2>
<p>Какие еще реальные задачи можно решать подобным этому подходом? Приведу список первого, что пришло в голову:</p>
<ul>
<li>Написать своё приложение под Android для поиска книги в магазине по фотографии обложки.</li>
<li>Приложение-экскурсовод, которое говорит что за здание на фотографии.</li>
<li>Простая модель идентификации человека по лицу.</li>
<li>Я думаю о том, как бы создать приложение для поиска похожих стилей в fashion-фото.</li>
</ul>
<p>А что еще можно сделать? Предлагайте в комментариях!</p>
<h2>Литература</h2>
<ul>
<li><a href="https://habrahabr.ru/post/120562/">Выглядит похоже. Как работает перцептивный хэш</a></li>
<li><a href="https://habrahabr.ru/post/122372/">Алгоритмы быстрого нахождения похожих изображений</a></li>
<li><a href="https://habrahabr.ru/post/198338/">Использование каскада Хаара для сравнения изображений</a></li>
<li><a href="https://habrahabr.ru/post/237307/">Как бороться с репостами или пара слов о перцептивных хэшах</a></li>
<li><a href="http://cs231n.github.io/convolutional-networks/">CS231n Convolutional Neural Networks for Visual Recognition</a></li>
<li><a href="https://keras.io/applications/">Applications - Keras Documentation</a></li>
<li><a href="http://cs231n.github.io/transfer-learning/">CS231n transfer learning</a></li>
<li><a href="https://github.com/senior-sigan/KawaiiSearch">Исходные коды Kawaii-Search</a></li>
<li><a href="http://kawaii-search.senior-sigan.net/">Kawaii-Search - Демка поиска похожих</a></li>
</ul>
            </content>
        </div>
    </div>
    

    <script src="/scripts/links_preview.js"></script>
</aside>

</main>
    <footer></footer>
  </div>
</body>

</html>