<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <meta property="og:site_name" content="Ilya&#39;s digital garden">

  <link rel="icon" type="image/png" href="data:image/png;base64,iVBORw0KGgo=">

  <link rel="stylesheet" href="/app.css">

  
  <meta property="og:title" content="Зачем учить машины?">
  <meta property="og:type" content="article">
  

  
  <meta property="article:published_time" content="">
  <meta property="article:author" content="/">
  

  <title>
    Зачем учить машины?
  </title>

  
</head>

<body>
  <nav><ul>
    <li><a class="internal-link" href="/"><b>Ilya&#39;s digital garden</b></a></li>
    <li><a class="internal-link" href="about.html">About</a></li>
    <li><a class="internal-link" href="archive.html">Archive</a></li>
</ul></nav>
  <div class="wrapper">
    <main>

<article>
  <div>
    <h1>Зачем учить машины?</h1>
    
    <time datetime="2017-06-30T12:00:00+06:00">
      Created on Jun 30, 2017
    </time>
    
  </div>

  <div id="notes-entry-container">
    <content>
      <blockquote>
<p>Компьютеры становятся все умнее. Ученые утверждают, что скоро они смогут разговаривать с нами.<br />
Дейв Барри. (Под “они”, я подразумеваю компьютеры, а ученые, судя по всему, так и не научатся с нами разговаривать)</p>
</blockquote>
<p>Прежде чем мы с вами пустимся в пучину больших данных, статистики, теории обучения и , возможно, даже философии, давайте вспомним, как развивалась в принципе вычислительная техника и как мы пришли к тому, что мы сейчас имеем.</p>
<h2>Механические вычислительные машины</h2>
<blockquote>
<p>Поскольку это недостойно таких замечательных людей, подобно рабам, терять время на вычислительную работу, которую можно было бы доверить кому угодно при использовании машины</p>
</blockquote>
<p><img alt="Копия арифмометра Лейбница" src="/assets/why-teach-machine/1_jPr_938zH7WkSWilHfcObA.jpeg" />
<em>Копия арифмометра Лейбница в <a href="https://ru.wikipedia.org/wiki/Немецкий_музей_(Мюнхен)">Немецком музее</a>.</em></p>
<p>В 17-ом веке замечательные математики Паскаль, Лейбниц и, вероятно, многие другие, уставшие от постоянных монотонных арифметических вычислений, построили <a href="https://ru.wikipedia.org/wiki/Арифмометр">механические арифмометры</a>, идею которых описал ни кто иной как Леонардо да Винчи еще в 15-ом веке. Всё было исполнено с использованием цилиндров, шестерёнок и прочих прелестных деталей.</p>
<p>Прогресс не стоял на месте. Жаккард придумал перфокарты для повторения каких-то шаблонов, а Бэббидж понял, что можно создать механическую программируемую перфокартами машину — аналитическую машину. Стартовал проект длиною во весь 19-ый век — создание разностной машины, использующей силу пара, в то время весьма популярного источника энергии. И как не вспомнить первую программистку Аду Байрон, которая помогала в создании этой чудо машины.</p>
<p><img alt="" src="/assets/why-teach-machine/1_0GiZx0RKwRFBPiER3ZpLcA.jpeg" />
<em>Копия разностной машины в <a href="https://ru.wikipedia.org/wiki/Музей_науки_(Лондон)">лондонском Музее науки</a></em></p>
<p>Примечательно то, что даже тогда, люди полагали, что им удастся создать мыслящую машину, в каком бы то ни было понимании процесса мышления. Единственное чего не хватало по их мнению — это шестерёнок, нужно просто добавить их чуть больше, чтобы производительность машины была достаточно высока.</p>
<blockquote>
<p>Машина будет иметь возможность мыслить, проявлять интеллектуальность, если будет достаточно производительной. XIX век.</p>
</blockquote>
<h2>Электромеханические и электронные машины</h2>
<p>В середине прошлого века стали создавать электромеханические вычислительные машины, использовали уже не шестеренки, а, например, лампы. Производительность по сравнению с аналитической машиной Бэббиджа стала просто невероятной, но интеллектуальности мы всё еще не наблюдали. А Тьюринг описал абстрактного вычислителя, тем самым формализовав процесс вычисления на компьютерах. Таким образом к 1960-м годам мы уже имели хорошо описанную и математически обоснованную область. Осталось только дело техники — улучшить производительность!</p>
<p>Если смотреть на развитие уже привычной нам электронной вычислительно техники, то можно условно определить следующие поколения:</p>
<ol>
<li>1940-ые — Электронные лампы</li>
<li>1950-ые — Транзисторы</li>
<li>1960-ые — Интегральные схемы</li>
<li>1970-ые — Микропроцессоры</li>
<li>1980-ые — Параллельные вычисления</li>
</ol>
<p>Сами по себе поколения нам не интересно разбирать, но интересно детальнее проанализировать концепции появившиеся в конце 70-ых годов, приведшие к так называемому пятому поколению.</p>
<h2><a href="https://ru.wikipedia.org/wiki/Компьютеры_пятого_поколения">Пятое поколение</a> вычислительной техники</h2>
<p>Опьяненные успехами развития электроники, Японские ученые решили, что вот теперь, применив распараллеливание вычислений, запущенных на кластере компьютеров, и используя логические языки программирования типа <a href="https://ru.wikipedia.org/wiki/Пролог_(язык_программирования)">Prolog</a> и языки обработки списков <a href="https://ru.wikipedia.org/wiki/Лисп">Lisp</a>, они смогут получить искусственный интеллект, достигнув определенной вычислительной мощности. И, самое интересное, их не остановил на полпути тот факт, что уже вышли новые процессоры, обладающие куда большей мощности, чем они предполагали, а компьютеры так и не обладали интеллектом!</p>
<p>В итоге, спустя десять лет разработки, было потрачено около 500 миллионов долларов, но ИИ так и не появилось. Давайте подумаем, в чём же заключалась проблема? Неужели опять в недостатке мощностей?</p>
<blockquote>
<p>Машина будет иметь возможность мыслить, проявлять интеллектуальность, если будет распределенной. XX век.</p>
</blockquote>
<h2>Проблема программного ИИ</h2>
<p>Когда мы пишем программу, то мы фактически фиксируем языком программирования некоторую нашу абстрактную идею о некотором факте из природы. Люди создают абстракции, интерпретируя своё восприятие этого мира, то есть они базируются на каких-то знаниях, чувствах, морали, <a href="https://ru.wikipedia.org/wiki/Запечатление">импринтах</a> и так далее. Получается, абстракции, которые фиксируются строгими искусственными <em>логичными</em> языками программирования (которые, кстати, противоречивы с точки зрения формальной логики, так как базируются на <a href="https://ru.wikipedia.org/wiki/Закон_противоречия">противоречивой</a> <a href="https://ru.wikipedia.org/wiki/Логика_Хоара">логике Хоара</a>, но это совсем другая история), не объективны хоть сколько-то. Разные люди скорее всего будут создавать разные абстракции, и это зависит не только от их мастерства программиста, аналитика, ученого.</p>
<p><img alt=" " src="/assets/why-teach-machine/1_kGSYV6 6R7OnXsFy7cTTvQ.jpg" /></p>
<p><img alt=" " src="/assets/why-teach-machine/1_WM8jBybO9wBSpWaAal0X4A.jpg" /></p>
<p>Найди несчетное множество отличий</p>
<p>А теперь представьте, что вас пригласили разрабатывать подсистему ИИ, способную отличать собаку от кошки. Вам показали две фотографии с кошкой и собакой. Представьте в голове, чем собака и кошка отличаются друг от друга. Теперь попробуйте мысленно формализовать эти идеи. Но, вдруг, вам показали две другие фотографии, которые вы не видели до этого никогда, и у вас, весьма вероятно, частично разрушатся предыдущие абстрактные идеи, на их смену придут новые, более точные, как вам кажется. Но, внезапно, отдел маркетинга понял, что еще надо научить отличать животных не только по фотографии, но и по звуку. Всё начинается сначала! И это еще не всё, настал момент разобраться в разных породах кошек и собак.</p>
<p>Из примера вы можете заметить, что мы с вам загнали себя в ловушку абстрактных воздушных замков. Если бы вы делали это задание в группе друзей, то, возможно, вы бы даже начали весьма горячий спор. Каждый новый пример частично ломает наши идеи, а путь исправления нам видится только в полном переписывании алгоритма.</p>
<blockquote>
<p>Путь исправления лежит через полное переписывание алгоритма. Знакомо?</p>
</blockquote>
<p>Почему это происходит? Почему не получается описать нечто раз и навсегда? Где же <a href="https://ru.wikipedia.org/wiki/Объективная_реальность">объективная реальность</a>, которую мы так хотим зафиксировать? А может такое быть, что мир слишком динамичен и разнообразен для наших закостенелых статических абстракций? Поэтому необходимо отыскать другие методы описания абстракций, которые не зависят от человеческого восприятия на столько, на сколько это вообще возможно. В этот момент мы можем подойти к идее машинного обучения.</p>
<p>Справедливости ради стоит отметить, что некоторый класс задач можно очень эффективно решать описывая эти статичные абстракции. Такие алгоритмы как правило очень эффективны, следовательно быстро работают. Например, поиск лиц на фотографии методом <a href="https://ru.wikipedia.org/wiki/Признаки_Хаара">каскадов Хаара</a>, <a href="http://www.ee.columbia.edu/~dpwe/papers/Wang03-shazam.pdf">идентификация музыки</a>, фильтрация сигналов и так далее.</p>
<h2>Новый подход к построению ИИ</h2>
<p>Вместо того, чтобы человек сам описывал с помощью языка программирования некоторую свою субъективную абстракцию, предлагается использовать компьютер для этих целей. Тогда вместо программирования конечного алгоритма, мы будем создавать алгоритм, который ищет алгоритмы (<em>именно ищет, а не создаёт</em>). Здесь я предлагаю вам ознакомиться со статьей 2001 года “<a href="http://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=sjim&amp;paperid=115&amp;option_lang=rus">Рефлексирующие программные системы</a>”. В ней авторы ставят вопрос почему программы до сих пор(2001 год) так и не стали интеллектуальными? Как наделить программы рефлексией, то есть способностью к самоулучшению?</p>
<blockquote>
<p>“Наиболее рациональный путь решения этой проблемы состоит в изучении того, как она решается живыми разумными системами в процессе их деятельности.”</p>
</blockquote>
<p>Для этого определяем некоторое начальное состояние системы и целевое состояние. Путь достижения целевого состояния не известен. Таким образом система должна отыскать каким-то образом этот путь, чтобы совершить переход между состояниями. Поиск может быть реализован как полный перебор чего-то. Если же цель сама по себе очень сложная и достижима разными путями, то мы, как и всегда, разбиваем задачу на подзадачи. Тем самым получаем иерархическую структуру(дерево) из целей, связанных между собой некоторыми путями для перехода. Вообразить это можно в виде пирамиды, в основании которой находятся цели решаемые алгоритмами некоторого первого уровня. Цели второго уровня решаются с помощью алгоритмов второго уровня, соответсвенно. Но что делает алгоритм с каждого следующего уровня этой пирамиды? Он выбирает алгоритм нижнего уровня для решения своей задачи.</p>
<blockquote>
<p>Когда мы пишем обычные программы, будь то вычисляющие сложные формулы или рисующие анимации на экране, мы создаем алгоритмы некоторого первого уровня.</p>
</blockquote>
<p>Можно сказать, что вся эта система из выбирающих друг друга алгоритмов, идущая к некоторой цели, обладает рефлексией и интеллектуальностью(если рассматривать когнитивную способность к обучению как интеллектуальную).</p>
<p>Вопрос в том, как создавать такие программы? Что они из себя представляют? Что такое поиск пути достижения цели или “подходящего” алгоритма? Что нас ждет на вершине пирамиды, если она существует? И где в этой пирамиде человек?</p>
<p>Как вы уже догадались, такие системы можно создавать с помощью машинного обучения.</p>
<h2>Машинное обучения</h2>
<p>Рассмотрим сразу пример простой задачи, с помощью которой можно легко объяснить суть маш. обуча.</p>
<p><img alt=" " src="/assets/why-teach-machine/1_qOJHpFzTNnDPLCvEBkEe7w.jpg" /></p>
<p>Допустим у нас есть данные о размерах чашелистика и лепестка большого множества цветов ириса. По этим данным мы хотим научить машину отличать цветы различного вида друг от друга. Мы <em>предполагаем</em><strong>,</strong> что существует некоторая <strong>скрытая закономерность</strong> между видом цветка и его <strong>характеристиками</strong>. Процесс же обучения — это поиск зависимостей между наблюдаемыми характеристиками и скрытыми. В терминах информатики все вычислимые функции есть суть алгоритмы, таким образом мы с вами можем сказать, что машинное обучение как алгоритм и есть алгоритм 2-го уровня ищущий алгоритмы 1-го уровня.</p>
<p>Может показаться, что теперь мы можем взять любые данные и загрузить их в условный google cloud, чтобы решить нашу произвольную задачу. Но не случайно у нас есть целая пирамида алгоритмов. Оказывается, что определенный алгоритм машинного обучения, как алгоритм поиска, может искать закономерности не в полностью произвольных данных. Получается так, что мы, люди, должны выбирать эти алгоритмы 2-го уровня <strong>сами</strong> под определенные структуры данных.</p>
<blockquote>
<p>Некоторые боятся, что их заменят скриптом.</p>
<p>Продвинутые боятся, что их заменят машинным обучением.</p>
<p>Просветленные выбирают алгоритмы машинного обучение. (шутка)</p>
</blockquote>
<p>Именно из-за этой пирамидности нет Единого Алгоритма, людям всё ещё есть что делать и нельзя просто так спросить в чём смысл жизни и получить ответ, отличный от “42”.(на самом деле это проблема постановки правильного вопроса к бытию, которой, кстати, занимается философия)</p>
<h2>Проблемы машинного обучения</h2>
<p>Факт того, что нужно выбирать алгоритмы под задачу и данные порождает зоопарк разных алгоритмов маш.обуча. и классов задач(регрессия, классификация, кластеризация, …), возникает проблема предобработки данных и выбора подходящего алгоритма. Но как происходит этот выбор? Для этого оценивают метрики качества предсказания и пытаются интерпретировать результаты предсказания, чтобы понять почему алгоритм принял какое-то решение. Метрик качества тоже может быть много разных, в одном случае это может быть обычная точность(accuracy) предсказания, которая считает сколько раз алгоритм ошибся. Может быть <a href="https://ru.wikipedia.org/wiki/ROC-кривая">хитрая метрика</a>, которая учитывает <a href="https://ru.wikipedia.org/wiki/Ошибки_первого_и_второго_рода">ошибки первого и второго рода.</a> А для задачи регресси, где предсказывают вещественные числа, можно считать величину отклонения от достоверного значения, или квадрат отклонения, или модуль… В общем вы уловили идею, есть нюансы.</p>
<p>Да, вы можете предположить, что можно написать алгоритм третьего уровня, который будет просто перебирать все метрики, алгоритмы_2 и как-то перемешивать данные, но стоит отметить, что это Полный Перебор по теоретически, неограниченному множеству вариантов. Нужны новые методы оптимизации, не те что применяются на втором уровне, а совсем другие. На сколько я понимаю их ещё нет. Но некоторые структуры, например, глубинные сети по сути своей скрывают внутри себя очень много слоев абстракций. На столько много, что нельзя сказать какой это “уровень” нашей воображаемой пирамиды. По всей видимости, поэтому глубокие сети сейчас действительно кажутся вот-вот-совсем интеллектуальными и, даже, обладающими “творчеством” или способностью создавать.</p>
<p>В любом случае, если вы ещё пишете алгоритмы первого уровня, то вас скоро автоматизируют. Не так давно нейросети научились <a href="https://nplus1.ru/news/2017/05/30/images">верстать по макетам</a>(sic!). Поэтому я зову вас на следующую ступеньку, где вы будете выбирать более абстрактные алгоритмы!</p>
<p>А продолжение философствования на тему того, что же это такое, “Искусственный интеллект”, вы можете прочитать <a class="wikilink" href="/2017-07-01-what-is-ai">2017-07-01-what-is-ai</a>.</p>
<p>Еще есть юмористические статьи про ML <a class="wikilink" href="/2017-09-28-ml-pasta">2017-09-28-ml-pasta</a> и <a class="wikilink" href="/2018-01-15-cipher-brain-questions">2018-01-15-cipher-brain-questions</a>.</p>
<p><img alt=" " src="/assets/why-teach-machine/1_qQcpjDzsW4emueLJG6_Vfw.jpg" /></p>
    </content>

    <side style="font-size: 0.9em">
    
</side>

  </div>
</article>

<hr>

<p>Here are all the notes in this garden, along with their links, visualized as a graph. <i>(Use ctrl + scroll to zoom
    in-out)</i></p>

<script src="/scripts/libs/d3.min.js"></script>

<div id="graph-wrapper"></div>
<aside id="link-preview-block">
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2018-01-15-cipher-brain-questions">
        <div class="tooltip-content">
            <h1>Проблема оцифровки мозгов</h1>
            <content>
                <blockquote>
<p>Когда мы уже оцифруем мозг и зальем его в сеть? Я хочу увидеть новые экзистенциальные проблемы, а то от этих уже наскучило.</p>
</blockquote>
<p><img alt="Ghost in the shell" src="/assets/cipher-brain-questions/1_KZyToLAvAk7gyJsVJFY_Ow.jpg" /></p>
<p>Я и <a href="https://medium.com/@KirillLeyfer">Кирилл Лейфер</a> на днях обсуждали в чате проблему оцифровки мозга. Мы задавали друг другу вопросы, даже не пытаясь на них ответить. Наиболее интересные из них мы решили выложить как статью, чтобы было потом интересно перечитать это.</p>
<hr />
<p>Чем искусственная цифровая нейросеть отличается от бывшей живой?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_LNLo30q_FJ8slO407qLBVA.jpeg" /></p>
<p>Не представляю, как можно доказать наличие самосознания у нейросети.</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_1SYPc7Lg8BgyZWlzszMjTg.jpeg" /></p>
<p>Как доказать идентичность исходного мозга оцифрованному? Какие вообще критерии у этой идентичности?</p>
<p>Является ли стирание жесткого диска уголовно наказуемым?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_0CnrrHCBLOqAegCEkQRTRw.jpg" /></p>
<p>Когда возникает сознание — возникают и права!</p>
<p>Когда можно переносить свой мозг, после совершеннолетия?</p>
<p>Как будут относиться к людям, которые не перенесли свой мозг?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_FIuE36XeERGiwWzTVUvdTQ.jpg" /></p>
<p>Что насчёт наследства, как делить имущество между копиями?</p>
<p>Обязательно ли создавать секс-робота — физическое воплощение цифрового мозга?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_CHuENPQxxHmO3NmF0lnivA.jpeg" /></p>
<p>Что насчёт брака человека и искусственного мозга, удалённо управляющего секс-роботом (ну или просто роботом)?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_fBrZ_kD_IXN75EEKk0pvJw.jpg" /></p>
<p>Что происходит при копировании мозга?</p>
<p>Кто отвечает за “выполнение” цифрового мозга?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_QtJyMOw73QmWhXrJ8NcD0g.jpg" /></p>
<p>Как ощущается выключение исполнения цифрового мозга?</p>
<p>Как ощущаются лаги выполнения функции мозга?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_xFWN64Lf7whoZ9fxl2gKEQ.jpeg" /></p>
<p>Давай представим общество, в котором люди каждый день на всякий случай делают бекап своего мозга и когда они умирают, то любой желающий может запустить этот бекап и спросить что-нибудь, поболтать, узнать некоторую инфу, как фотография или урна с прахом, но только отпечаток мозга. А каково это общаться самому со своими бекапами?</p>
<p>Считается ли пыткой модификация нейросети для подачи на вход импульсов боли, страха и неудовольствия?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_VnloudWDCyIsNtcoxgyZRw.jpeg" /></p>
<p>Законно ли модифицировать нейросеть? Например, увеличил вес какой-то связи — и получил более разговорчивую версию, которая после смерти сообщила тебе ноу-хау.</p>
<p>Теоретически можно запустить мозг на сверх быстром компьютере, как тогда будет ощущаться время?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_iAaQcRMMHMym6mYcppP3cw.jpg" /></p>
<p>> Думаю, что внутреннее время будет течь “обычно”, а вот инфа, поступающая на вход из внешнего мира, будет тормозить, казаться замедленной. А cо стороны покажется что цифровой мозг прожил миллион лет, а реально прошло пару минут.</p>
<p>> Это можно использовать для прорывных открытий, только внутри симуляции НИИ.</p>
<p>Будут ли психологические расстройства у нейросети и смогут ли их чинить?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_ZbJwbQgATOeZJfb3dsNFeQ.jpeg" /></p>
<p>Как долго искусственный мозг сможет существовать?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_imB5xqHd8jDYKGfTiZXyyw.jpg" /></p>
<p>Возможно ли отличить мир аналоговый от цифрового?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_uuXjkfoF7-0NrVuv-Q17dg.jpeg" /></p>
<p>Как человек поймет, что его перенесли в цифровой мир? Например, его насильно перенесли когда он спал.</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_aP0UoWGGpywNIQUH2KA2OA.jpg" /></p>
<p>Будут ли видеть сны цифровые компы? Смогут ли они достигнуть осознанных сновидений?</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_-StB59uKvNlQP91EhrsvKg.jpg" /></p>
<p>Цифровой мозг будет возможен когда создадут диски с бесконечной памятью. Или с такой особенностью что ты извне не можешь его полностью считать. И только объединение харда-софта дадут именно этот цифровой мозг. Новые копии будет невозможно создать так как диск невозможно считать полностью. Тогда это уживается с концепцией квалиа.</p>
<p>> Мне кажется, что бесконечная память не нужна — наше-то сознание располагается внутри конечных нейронов.</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_7wFq6kGbypJ-7voWH-LwYA.jpg" /></p>
<p>> Ты на самом деле не знаешь то, где твоя память расположена. Ответа на этот вопрос нет. Хоть и говорят что какой-то отсек мозга отвечает за отдельную память. Но что если наш мозг это “антенны”. И сегменты которые хранят память на самом деле обрабатывают закодированную память, что к нам приходит.</p>
<p><img alt=" " src="/assets/cipher-brain-questions/1_9PRa1o0oDs4FAGR8deT_pA.jpg" /></p>
            </content>
        </div>
    </div>
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2017-09-28-ml-pasta">
        <div class="tooltip-content">
            <h1>Паста про машинное обучение</h1>
            <content>
                <p>Ща будет простыня про ИИ и машобуч.</p>
<p>Короче, я решил пойти на курс по машинному обучению, это когда берешь данные какие-то, предполагаешь что там есть закономерности, связи или еще что-то, потом вспоминаешь Матан, из-за которого ты едва ли не пошел на метан, ТВиМС и еще чё-то с универа, думаешь такой сам сначала над закономерностями, приблизительно прикидываешь, что они там есть, а потом даешь Компу задачу, типа тут где-то есть закономерность какая-то, попробуй-ка её найти, я в тебя верю, и уходишь пить чай или спать, а комп за тебя всё решает. Ессно, он находит некоторую закономерность, возможно, даже ту о которой ты и не предполагал, как в том анекдоте про танки на зеленом фоне, но главное, что качество замеченной закономерности <em>хорошее</em>. Далее — круче, ты думаешь как бы так сделать, чтобы тебе не надо было искать простые закономерности, а только большие паттерны, а машина сама уже решала какие признаки важные, какие нет и так далее. Короче, пусть эта машина сама РЕФЛЕКСИРУЕТ над своими ошибками, а не ДАТАСАЕНТИСТ страдает вечерами и думает, что ему бы такого еще сделать с признаками, перемножить с запорожцем и разделить на блудницу, и возвести в айфон? «Какого черта я этим занимаюсь», — думает бедный датасатанист, — «я хочу, чтобы машина сама всё сделала». Так и живем, так и развиваем МЛ. Благодаря этому появились просто бомбические технологии, типа Prisma, где НЕЙРОСЕТОЧКИ научились «перерабатывать» фотки под стиль других произведений искусства, или всякие там яндекс музыки генерируют «Нейронную оборону», или Google ассистент-ка говорит чуть менее мерзким голосом. Ясно что там уже люди упоролись на более высоком уровне абстракции, чем при предсказании кредитного скора по информации о прошлых кредитах. А МЫ то что тут можем СДЕЛАТЬ? — Начать ИЗУЧАТЬ с основ машинное обучение и пытаться-пытаться догнать и понять новые модели и техники, чтобы когда к вам внезапно придут и скажут: «Милостивый сударь, а можно ли скрестить block-chain с бобром и анализировать твиты так, чтобы предсказывать популяцию крыс в нью-йоркском метро?» — а вы такие, — «Пф, да как два пальца, ща сделаем стопицот слоев нейросети и всё будет зашибись». А потом, когда все друзья уедут в отпуск на юга, где нет интернетов, и вам будет не с кем болтать, то вы возьмете всю историю вашей переписки с бывшей подружкой, из блокчейна конечно же, и обучите RNN-LSTM-DEEP нейросеть, чтобы счастливыми одинокими вечерами было с кем разговаривать о проблемах интеграции блокчейна в медицине. Но тут вас внезапно начали одолевать какие-то назойливые ычары!! Но что же делать, вам хочется пойти помайнить Эфир на кластере ПЕЧей, а не общаться с ними, и тут вы берете опять вашу RNN-LSTM-DEEP-dark-как-ваша-душа сеточку и отправляете ее общаться с ычарами. Конечно, иногда вам придётся ходить в магазин за покупками, но вы же знаете как устроен робот у Boston Dynamics, поэтому вы делаете свою ~Waify~ ~Служанку~, чтобы она купила за вас ОРГАНИЧЕСКУЮ картошку, лучок, петрушечку, курочку и дома приготовила супчик, пока вы делаете бота с <em>Искусственным Интеллектом</em> для вашей новой поделки, в которой вы сможете, надев очки виртуальной реальности от гугла в картонной упаковке, очутиться в фэнтезийном мире с эльфийками и прочими темными властелинами, но тут приезжают ваши друзья, кожаные ублюдки, из отпуска и говорят, что у них появилась идея для очередного стартапа.</p>
            </content>
        </div>
    </div>
    
    <div style="opacity: 0; display: none;" class="tooltip-wrapper" data-page-url="/2017-07-01-what-is-ai">
        <div class="tooltip-content">
            <h1>Что такое искусственный интеллект</h1>
            <content>
                <p>За последние 10 лет мы с вами можем наблюдать бурный рост интереса к машинному обучению и искусственному интеллекту, если верить Google Trends (статистика по поисковым запросам).</p>
<p><img alt="Image for post" src="/assets/what-is-ai/1_pOF5ydO3GjkfPnAS3r1XDQ.png" /></p>
<p>Обратной стороной излишней популярности ИИ стало то, что теперь термин «интеллектуальный» стали использовать слишком часто и, возможно, неуместно. Произошло это главным образом благодаря успехам в области машинного обучения, которое было определено ещё в 1950-е годы, благодаря чему внедрять его стало достаточно просто.</p>
<blockquote>
<p>Но действительно ли мы можем употреблять термин искусственный интеллект к тому, что внутри себя использует машинное обучение?</p>
</blockquote>
<p>Можно ли говорить, что машинное обучение есть метод создания искусственного интеллекта? Для того, чтобы разобраться в этой проблеме предлагается рассмотреть исторический путь развития искусственного интеллекта и отдельно машинного обучения, чтобы понять, почему именно в наши дни мы наблюдаем растущую популярность к этим наукам, и объемы их реального применения в жизни. Как итог, проанализируем, достигли ли мы успехов в ИИ благодаря методу машинного обучения или произошла подмена понятия ИИ.</p>
<h2>Терминология. Искусственный интеллект</h2>
<p>Обратимся к изначальным смыслам отдельных слов термина ИИ. Искусственный — калька с немецкого слова, обозначает нечто не природное и сделанное наподобие подлинного (толкование Ожигова). Английская версия artificial идет от французского и латинского — сделанное человеком или относящееся к искусству(то что делает человек). Интеллект — из латинского познание и понимание, но в греческом переводе «нус» — это ум, означающий начало сознания и самосознания в космосе и человеке, принцип интуитивного знания. Интересно заметить, что в философском словаре говорят, что интеллект противопоставляется другим способностям человека, таким как чувство, воля, интуиция и воображение, тем самым ограничивая интеллект лишь только функцией рационального познания.</p>
<blockquote>
<p>Таким образом искусственный интеллект — это созданный человеком функционал рационального познания по образу человеческого или, если из греческого, это созданное человеком нечто с сознанием и самосознанием.</p>
</blockquote>
<p>Сам термин ИИ изначально ввёл Джон Маккарти на конференции в Дартмунском университете в 1956 году. И позже, в 2007 году, он дал расшифровку того смысла, который он вложил в это понятие. По Маккарти, ИИ — это раздел науки и инженерии, занимающийся изучением и построением интеллектуальных систем. Интеллектуальность — это вычислительная часть способности добиваться заданных целей. Маккарти заключает, что ИИ это не симуляция человеческой интеллектуальности в полной мере, а только «некоторым» образом. [6] Интеллектуальность в данном контексте не означает, что один человек умнее другого, но то, что нечто обладает мыслью или способом рассуждать.</p>
<h2>Терминология. Машинное обучение</h2>
<p>В качестве машины будем рассматривать любое цифровое устройство. Обучение — процесс передачи исторического опыта. Learn — от древне германского — следовать или искать-прокладывать путь (track).</p>
<blockquote>
<p>Машинное обучение — процесс передачи опыта цифровому устройству, посредством поиска некоторой закономерности в наборе прецедентов.</p>
</blockquote>
<p>Различают два вида обучения — индуктивное по прецедентам и дедуктивное, то есть формализация знаний экспертов.</p>
<h2>Тьюринг и игра в имитацию</h2>
<p>Исторически считается, что первой работой в области философии искусственного интеллекта стала работа Алана Тьюринга «Вычислительные машины и интеллект», в которой он старался ответить на вопрос «<a href="http://www.etheroneph.com/files/can_the_machine_think.pdf">Может ли машина мыслить?</a>» . Рассмотрим то, как автор дал определение интеллекта в этой публикации.</p>
<p>Вместо того, чтобы водить явные дефиниции терминам «мыслить» и «машина» Тьюринг заменяет весь поставленный вопрос на некоторый другой. Для этого он вводит описание «игры в имитацию», в которой участвуют три человека: мужчина (A), женщина (B) и третья сторона, задающая вопросы (С). Цель игры для задающего вопросы — это определить пол игроков A и B, общаясь с ними по телеграфу(почте или через посыльного), то есть без прямого контакта. В свою очередь игрок A пытается ввести C в заблуждение, чтобы он сделать неверные выводы, а игрок B, наоборот помогает C сделать верное решение. В итоге первоначальный вопрос «Может ли машина мыслить?» заменяется на «Что произойдет, если в этой игре вместо А будет участвовать машина?»[4]. Сможет ли машина эффективнее чем человек обманывать C, и разгадает ли C в игроке машину по его поведению? Если сможет, то Тьюринг считает, что машина может мыслить, так как она понимает то, о чем идёт речь в беседе. Для нас интересно в этой постановке вопроса то, что здесь сопоставляется способность человека мыслить с его поведением. То есть Тьюринг задался целью спроектировать такую машину, которая сможет вести себя как человек. Для определения того, на сколько машина похожа в своём поведении на человека, он и предлагает использовать игру в имитацию.</p>
<p>Предложенная Тьюрингом игра и вопрос представляют собой некоторую версию операционализма, в которой быть интеллектуальным, то есть обладать мыслью и способностью к размышлению, означает способность системы пройти Тест. [7] Другими словами, у системы есть набор входов и набор выходов, человек подаёт определенные сигналы на вход и ожидает увидеть некоторый сигнал на выходе. Интеллект рассматривается как черный ящик или математическая функция с аргументами и значениями, предполагая, конечно, что сознание может быть механизировано и формально выражено через некоторую вычислимую функцию(так как иначе эту функцию не выразить в терминах полноты по Тьюрингу, что требуется для вычислимости на цифровом компьютере). Однако, такая формулировка через операционализм становится предметом затруднений. Очевидная проблема состоит в доверии к человеку-судье, к его беспристрастному, но субъективному суждению. Кроме того, как показала практика, можно создать абсолютно не интеллектуальную программу-психотерапевта, способную обмануть человека-судью.</p>
<p><img alt="Современная версия программы Eliza" src="/assets/what-is-ai/1_ftENk81nD4ip1bWxz42Wlw.png" /></p>
<p>Джозеф Вайзенбаум продемонстрировал это в созданной им программе Элиза в 1966 году. Она содержала наборы правил для разбора предложений, с помощью которых программа определяла в предложениях ключевой объект и переспрашивала судью по определенному шаблону про этот объект. Например, на фразу «Все надо мной смеются.», программа спросит «Как вы думаете, кто в большей степени?». Здесь стоит заметить, что программа не понимает смысла фразы «смеются надо мной», она просто видит ключевое слово «все» и задает совершенно общий вопрос. Если провести аналогию, то программы подобного типа работают как зеркала — они отражают обратно человеку тоже самое, что он сказал, слегка видоизменив предложения. Понимание у зеркала того, что оно отражает, отсутствует. Тем не менее это не останавливало, а даже вдохновляло, инженеров создавать такие «зеркала», задачей которых был обман человека-судьи. От части из-за обилия таких программ, к 1980-м годам наступила первая «зима» ИИ: у человечества было много программ способных пройти тест Тьюринга, но неспособных к другой интеллектуальной деятельности.</p>
<p>Исходя из двух проблем — субъективности судьи и возможность его обмана, единственным решением остаётся каким-то образом убрать субъективный элемент из тестирования. Если будет возможно выделить объективные факторы мышления, осмысления, намерения осмыслить, тогда будет возможно применить объективный метод тестирования. Дальнейший анализ и критику определения интеллекта по Тьюрингу можно вести через сравнение бихевиоризма и операционализма с психологизмом, как это было предложено у Неда Блока в статье «Психологизм и бихевиоризм»[7], но мы сконцентрируемся на последствиях концепции Тьюринга.</p>
<h2>Сильный и слабый ИИ</h2>
<p><img alt="Слабый vs Сильный" src="/assets/what-is-ai/1_S2HNaurzLGnLkCPZkLau7Q.png" /></p>
<p>Если Тьюринг принимал гипотезу о возможности ИИ и предложил метод тестирования, то Джон Сёрл задался вопросом о том, возможно ли создать цифровой компьютер, который будет способен понимать, например, тексты. Прежде всего Сёрл в своей работе «<a href="http://www.alt-future.narod.ru/Ai/searle1.htm">Сознание, мозг и программы</a>» [1] ввёл два новых термина: Слабый ИИ и Сильный ИИ. Ценность Слабого ИИ состоит в том, что он становится некоторым инструментом, с помощью которого мы можем более точно и строго ставить и проверять гипотезы при изучении феномена сознания. С другой стороны, Сильный ИИ — это некоторый компьютер, запрограммированный особым образом, на самом деле обладающий сознанием, в том смысле, что компьютер действительно понимает смысл и обладает некоторыми когнитивными состояниями. В этом случае Сильный ИИ самим своим существованием объясняет устройство сознания.</p>
<p>Можно ли создать Сильный ИИ написав программу, исполняемую на машине Тьюринга?</p>
<blockquote>
<p>Так вышло, что кроме теста, Тьюринг сформулировал математическую модель абстрактного исполнителя. Стоит отметить, что существует несколько эквивалентных моделей, таких как лямбда-исчисления Чёрча, машина Поста и другие. Эти системы создавались для формализации и анализа понятия вычислимости. Сейчас все компьютеры представляют собой машины Тьюринга-Поста. «Другими» могут считаться квантовые компьютеры.</p>
</blockquote>
<p>Такая машина всегда работает по строго заданному алгоритму в соответствии с какими-то правилами перехода между состояниями, её ещё называют детерминированной машиной. На машине Тьюринга можно реализовать любую вычислимую функцию, но, что интересно, это утверждение скрывает внутри себя тот факт, что в природе существуют и нереализуемые на ней функции, то есть алгоритмически неразрешимые. Вполне возможно, что сознание, как некоторая программа, представляет собой невычислимую функцию, тогда весь спор о возможности создания Сильного ИИ на цифровом компьютере становится бессмысленным.</p>
<p><img alt="Кадр из фильма «Китайская комната»" src="/assets/what-is-ai/1_hGbz7l9ZhNvsh-DzBSgd2g.jpeg" /></p>
<p>Джон Сёрл в своей работе [1] апеллирует против вычислимости сознания, но особенным образом. Для этого он определяет «Китайскую Комнату». В комнате сидит человек, который не знает китайский язык, но знает английский. Ему дают три карточки с китайскими символами вместе с инструкциями на английском языке, которые позволяют ему обрабатывать китайские символы, чтобы писать новые китайские символы. Те кто ему дают эти карточки, называют их «рукописью», «рассказом» и «вопросами», а написанные человеком символы — «ответами». Но человек в комнате этого даже не подозревает и не осознаёт. Появляется ли понимание китайского языка или сути этих карточек у человека в комнате? Сёрл отвечает, что не появляется никакого осознания, так как человек просто следует инструкциям. Сёрл описывает происходящее, как соревнование между «программистами» — теми людьми, которые создают инструкции, и теми, кто создают эти карточки. Человека в комнате можно рассматривать, как инстанциацию некоторой компьютерной программы.
Из мысленного эксперимента Сёрл делает следующие выводы по поводу Сильного ИИ:</p>
<ol>
<li>Сильный ИИ может иметь те же входы и выходы, что и носитель китайского языка. Может давать правильные ответы на вопросы благодаря инструкциям. Но понимания рассказов на китайском у компьютера не появляется, так же как и у человека следовавшего инструкциям.</li>
<li>Сильный ИИ не даёт достаточного объяснения феномена понимания, поскольку этого самого понимания и нет у него. Оппоненты могут сказать, что как раз то, что происходило в комнате и по существу является пониманием текстов.</li>
</ol>
<p>Из результатов этого мысленного эксперимента в итоге Сёрл утверждает, что программа, то есть набор некоторых инструкций, сама по себе не может мыслить и обладать когнитивными способностями, так как любая программа есть суть манипуляция с формальными символами, которая не обладает интенциональностью(намерение). Фактически это синтаксический разбор, но не семантический анализ.</p>
<p>Тем не менее, Сёрл уверен, что машины могут мыслить, как минимум люди, представляя собой некоторую форму «особенных машин». Поэтому, чтобы создать искусственное мышление, нам нужно повторять мозг человека и устройство его нервной системы. Естественно, это основывается на гипотезе, что определенная форма материи начинает обладать сознанием, то есть сознание не представляет собой какую-то отделимую и совершенно не связанную с телом напрямую субстанцию, как, например, полагал Декарт.</p>
<p><img alt=" " src="/assets/what-is-ai/1_Gu1gjmd5W8whggjqT3_19A.jpg" /></p>
<p>Во времена Декарта была весьма популярна гипотеза механистического устройства мира, тогда все были в восторге от автоматонов и надеялись создать человека-автоматона.</p>
<h2>Рефлексирующие системы</h2>
<p>Не смотря на большой интерес к ИИ и уже развитой философской теории к началу 21 века, можно было легко заметить, что в прикладной области так и не появились хоть сколько-то интеллектуальные программы, но в теории информатики всегда провозглашался тезис, что программы должны становиться всё более сложными и интеллектуальными. Группа ученых(В.В. Ващенко, Е.Е. Витяев, Н.Г. Загоруйко и другие) из Новосибирска заметили эту актуальную проблему и решили обосновать в публикации «Рефлексирующие программные системы» почему она возникла, что из себя представляет интеллектуальная система и какими путями можно начать строить такие системы. [2]</p>
<p>Ключевой способностью интеллектуальных систем, например живых, они обозначают способность к рефлексии (одной из составляющих частей процесса мышления) и эмоциям. Необходимо каким-то образом понять механизмы, с помощью которых можно будет создавать программы, способные к самосовершенствованию, то есть рефлексии. В противоположность этому, почти всё, что создает индустрия едва ли приспособлено к самоулучшению, даже больше, незначительное изменение предметной области приводит к полному переписыванию программного кода. Такой подход будет становиться менее успешным, так как сейчас и в будущем, по всей видимости, реальность будет всё более сложной для описания и всё более разнообразной и быстроменяющейся.</p>
<p>Рассмотрим возможную структуру рефлексирующей системы. Для описания состояния системы вводят пространство состояний некоторых агентов. Выделяется некоторое исходное и целевое состояние системы. Задача перевода состояния системы из исходного в целевое порождает деятельность, которую будем называть целеустремленной. Цель известна, но неизвестен путь к её достижению. Некоторый примитивный агент для достижения цели может применить полный перебор некоторого пространства вариантов, а рефлексирующий агент будет обучаться на опыте и двигаться целенаправленно по наиболее экономически выгодному маршруту к цели. На этом пути можно определять дополнительные подцели для поиска первого шага перехода между состояниями. В результате рефлексирующую систему можно представить в виде некоторой иерархии, где с одной стороны есть иерархия подцелей, а с другой — иерархия некоторых программ, каждая из которых может решать некоторые базовые задачи. Предположим, что у нас существует некоторая программа M1 первого тип, умеющая решать класс задач Z1, применяя над данными D1, последовательность подпрограмм алгоритма A1. Если мы хотим, чтобы M1 произвела улучшения себя по мере накопления опыта, тогда нужно построить некоторую программу M2, задача которой состоит в наблюдении за работой M1 над данными и подбором рекомендации по её совершенствованию. В свою очередь программа M2 тратит энергетические ресурсы, объем которых можно минимизировать за счет оптимизации M2. Для этого нужно построить третий уровень подпрограмм и так далее. Кстати, энергетический ресурс было предложено рассматривать как аналог эмоциям — это ресурс необходимый для оценки успешности программы в каждый момент времени. Таким образом система обладает качеством рефлексии и эмоциями.</p>
<p>Другими словами иерархию подпрограмм можно описать следующим образом: для решения определенной задачи и достижения цели, алгоритмы высокого уровня на основе опыта самостоятельно выбирают алгоритмы низкого уровня, таким образом осуществляется рефлексия — самосовершенствование этой иерархической системы.</p>
<p>Но мы приходим к интересной проблеме — какого размера эта иерархическая структура, конечна ли она или нет, кто выбирает самый первый алгоритм (вершину), с которого все запустится? Где в этой иерархии находится человек или он находится где-то во вне? Ответы на эти вопросы, по всей видимости, станут сразу же ответами на вопрос о том, как создать Сильный ИИ и что такое сознание. Эти вопросы трансцендентные и, вероятно, по теореме Гёдела о неполноте арифметики не могут получить ответа в нашей системе. Тем не менее можно предположить, что создавая такие рефлексирующие системы и увеличивая их размер, мы будем замечать всё более возрастающие интеллектуальный способности этих систем, причем в некотором предельном варианте такую систему мы уже сможем назвать достаточно интеллектуальной или ИИ почти наверное.</p>
<p>Существуют ли сейчас подобные иерархические рефлексирующие системы? Ответ положительный, так как ими можно считать алгоритмы машинного обучения.</p>
<h2>Машинное обучение</h2>
<p><img alt="Кадр из мультика “Футурама”" src="/assets/what-is-ai/1_MmisabA88rnQeJfULviwiQ.png" /></p>
<p>Как сказал Артур Сэмюэль МО даёт компьютерам способность учиться без непосредственного программирования. В таком случае нет необходимости придумывать математические модели и строить абстракции каких-то явлений, так как с помощью МО можно некоторым образом перенести эмпирический опыт связанный с этим явлением и ожидать, что компьютер уловит некоторые закономерности, так же как мы надеемся, что ребенок правильно воспринял уроки. Формальное определение сводится к тому, что суть МО — это поиск некоторого функционала или закономерности в природе из множества всевозможных алгоритмов. Другими словами у нас имеет место задача по выбору алгоритма. А в предыдущей главе о рефлексирующих системах, мы описали систему строящуюся на основе этих принципов. Если проводить аналогии, то обычное программирование алгоритмов, то есть создание некоторых абстракций с помощью экспертного мнения человека, можно назвать процессом выбора алгоритма первого уровня иерархии. В свою очередь, если смотреть обще, то любой алгоритм машинного обучения представляет собой агента со второго уровня иерархии, так как алгоритмы обучения производят поиск и выбор наиболее подходящих под эмпирические данные функционалов. Но в области машинного обучения достаточно быстро пришли к проблемам подбора гиперпараметров и выбора подходящей модели обучения, а этот факт ни что иное как признак существования алгоритмов третьего уровня. Можно предположить, что глубинные нейронные сети представляют собой самые высокие агенты из иерархии рефлексирующих систем на данный момент, так как внутри себя они явным образом содержат множество иерархии.</p>
<p><img alt="Google image net" src="/assets/what-is-ai/1_mrSYY8upm6Ls4gCVfLOHTw.png" /></p>
<p>Долгое время у инженеров и учёных были проблемы по обучению таких сложных иерархий, но в 2007 году в статье «Learning multiple layers of representation » было показано как это можно эффективно делать, и именно поэтому сейчас мы можем наблюдать бурное развитие этой отрасли.</p>
<p>Хотя машинное обучение по сути своей и остаётся программой, но так как для её построения человеку уже не нужно вручную выделять абстракции и так как используются методы рефлексии, можно предположить, что на данный момент это один из самых прогрессивных методов создания систем обладающих интеллектуальностью, пусть и не в смысле Сильного ИИ. Вопрос о создании Сильного ИИ можно отложить на тот момент, когда будет доступно использовать не только Тьюринг полные компьютеры, а, например, квантовые, у которых пространство возможных для решения задач намного шире.</p>
<h2>Заключение</h2>
<p>Философия сознания и искусственного интеллекта за последние 60 лет прошла долгий путь от бихевиористических подходов в Тесте Тьюринга до теории рефлексирующих систем и машинного обучения. За это время исследователи искали способы создания ИИ методом программирования, построения математической модели сознания, полагая что оно представимо в виде вычислимого алгоритма. Такой подход привел к «зиме» ИИ и пережил много критики и опровержений, например, в работе Сёрла, который полностью опроверг возможность программного ИИ с помощью мысленного эксперимента с «Китайской комнатой». Но с середины 2000-ых годов благодаря успехам в области глубинных нейронных сетей и машинного обучения в целом стало известно каким методом можно строить рефлексирующие системы, то есть системы способные к самоулучшению и обучению. Если рассматривать интеллектуальность как когнитивную способность к познанию, то методы машинного обучения в предельном случае позволяют нам создавать как минимум нечто среднее между сильным и слабым искусственным интеллектом. Поэтому можно считать, что машинное обучение представляет собой некоторый метод построения искусственного интеллекта в предельном случае.</p>
<h2>Список литературы</h2>
<ol>
<li>Searle J. Minds, brains, and programs // Behavioral and brain sciences. — 1980. — Вып. 3. — С. 417–457.</li>
<li>Ващенко А. Н. Рефлексирующие программные системы / А. Н. Ващенко, Е. Е. Витяев, Н. Г. Загоруйко, А. А. Мальцев, Н. Н. Непейвода, Д. Е. Пальчунов, С. Г. Пыркин, А. В. Ткачев. // Сиб. журн. индустр. матем. — 2001. — Т. 4, № 1. — С. 22–28</li>
<li>Пенроуз Р. Новый ум короля. — М.: Едиториал УРСС, 2003. — 339 с.</li>
<li>Тьюринг А. Может ли машина мыслить? (С приложением статьи Дж. фон Неймана “Общая и логическая теория автоматов”). — М.: Государственное издательство физико-математической литературы, 1960. — 67 с.</li>
<li>Хокинс Д., Блейксли С. Об интеллекте. — М.: Вильямс, 2007. — 240 с.</li>
<li>What is Artificial Intelligence? — 2007. — URL: <a href="http://www-formal.stanford.edu/jmc/whatisai/whatisai.html">http://www-formal.stanford.edu/jmc/whatisai/whatisai.html</a> (дата обр. 10.06.2017)</li>
<li>Block N. Psychologism and Behaviorism // Philosophical Review. — 1981. — Вып. 90. — С. 5–43.</li>
<li>Сэмюэл А. Некоторые исследования в машинном обучении, используя игру шашек // IBM Journal. — 1959. — № 3. — С. 210–229.</li>
</ol>
<p><em>Изначально эта статья была оформлена мною как реферат по философии науки под названием</em> <a href="https://yadi.sk/i/44-3ZNt_3S56RM"><em>“Машинное обучение как метод создания искусственного интеллекта”</em></a></p>
            </content>
        </div>
    </div>
    

    <script src="/scripts/links_preview.js"></script>
</aside>

</main>
    <footer></footer>
  </div>
</body>

</html>